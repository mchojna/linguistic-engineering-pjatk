{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32s2BT904GEe"
   },
   "source": [
    "# Ćwiczenia 2\n",
    "\n",
    "Ponownie zaimportuj pakiet nltk (natural language toolkit)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "3aqFlDVd4OLl"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/mchojna/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Error loading stop: Package 'stop' not found in index\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mchojna/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pip install nltk\n",
    "#w colabie zbędne\n",
    "import nltk\n",
    "# nltk.download() \n",
    "nltk.download('punkt')\n",
    "nltk.download('stop')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m22byVdnsMQZ"
   },
   "source": [
    "# Tokenizacja na większe części\n",
    "\n",
    "Teraz podzielmy tekst na zdania.\n",
    "\n",
    "Każdy pakiet ma zaszyty sposób podziału, na przykład to czy kropka wchodzi w zdanie czy nie, czy spacja przed czy po, a może w ogóle bez.\n",
    "\n",
    "Te decyzje wydaja się błahe ale niewłaściwy podział może bardzo przeszkadzać w  dalszej pracy z tekstem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1P6Tzi-8sSZc",
    "outputId": "52a224f4-7a96-4474-b386-48d17198abf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Podział na zdania prezentuje się tak:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Teraz potrzebuję wiecej niż jedno zdanie.',\n",
       " 'Na przykład dwa.',\n",
       " 'Albo jeszcze lepiej trzy!']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_zdania=(\"Teraz potrzebuję wiecej niż jedno zdanie. Na przykład dwa. Albo jeszcze lepiej trzy!\")\n",
    "print(\"Podział na zdania prezentuje się tak:\")\n",
    "nltk.sent_tokenize(text_zdania)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bvQlo_Pgsrl0"
   },
   "source": [
    "# Zadanie 1\n",
    "> 'Łazik NASA Curiosity zarejestrował na Marsie zjawisko wiru pyłowego, zwane też \"diabłem pyłowym\". Wir, który udało się nagrać jest półprzezroczysty, jednak dobrze widoczny w kamerze łazika, badającego krater Gale. Zjawisko powstaje nad suchym obszarem w wyniku silnej konwekcji. Jest częste na Ziemi, tworzy się także na Marsie. Półkula południowa Czerwonej Planety nagrzewa się, szykując na marsjańskie lato. To prowadzi właśnie do konwekcji i wirów. Silne diabły są w stanie wysoko wnosić kurz i piach, tworząc potężne wiry pyłowe. Na Marsie są one jednak krótkotrwałe i dość ograniczone w obserwacji. Pierwszy raz to zjawisko na Czerwonej Planecie odkryto w latach 70. XX w., w trakcie misji sond Viking.'\n",
    "\n",
    "* Tekst podzielić na zdania. \n",
    "\n",
    "* Policzyć wyrazy w kazdym zdaniu\n",
    "\n",
    "* Wyświetlić najkrótsze i najdłuższe zdanie\n",
    "\n",
    "* Porównać wynik przed i po eliminacji stopwordsów (można uzyc dowolnej listy) oraz po usunięciu interpunkcji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "2rUMFXcJuaPy"
   },
   "outputs": [],
   "source": [
    "#kod do zadania 1\n",
    "text = 'Łazik NASA Curiosity zarejestrował na Marsie zjawisko wiru pyłowego, zwane też \"diabłem pyłowym\". Wir, który udało się nagrać jest półprzezroczysty, jednak dobrze widoczny w kamerze łazika, badającego krater Gale. Zjawisko powstaje nad suchym obszarem w wyniku silnej konwekcji. Jest częste na Ziemi, tworzy się także na Marsie. Półkula południowa Czerwonej Planety nagrzewa się, szykując na marsjańskie lato. To prowadzi właśnie do konwekcji i wirów. Silne diabły są w stanie wysoko wnosić kurz i piach, tworząc potężne wiry pyłowe. Na Marsie są one jednak krótkotrwałe i dość ograniczone w obserwacji. Pierwszy raz to zjawisko na Czerwonej Planecie odkryto w latach 70. XX w., w trakcie misji sond Viking.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Łazik NASA Curiosity zarejestrował na Marsie zjawisko wiru pyłowego, zwane też \"diabłem pyłowym\".',\n",
       " 'Wir, który udało się nagrać jest półprzezroczysty, jednak dobrze widoczny w kamerze łazika, badającego krater Gale.',\n",
       " 'Zjawisko powstaje nad suchym obszarem w wyniku silnej konwekcji.',\n",
       " 'Jest częste na Ziemi, tworzy się także na Marsie.',\n",
       " 'Półkula południowa Czerwonej Planety nagrzewa się, szykując na marsjańskie lato.',\n",
       " 'To prowadzi właśnie do konwekcji i wirów.',\n",
       " 'Silne diabły są w stanie wysoko wnosić kurz i piach, tworząc potężne wiry pyłowe.',\n",
       " 'Na Marsie są one jednak krótkotrwałe i dość ograniczone w obserwacji.',\n",
       " 'Pierwszy raz to zjawisko na Czerwonej Planecie odkryto w latach 70.',\n",
       " 'XX w., w trakcie misji sond Viking.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13, 16, 9, 9, 10, 7, 14, 11, 11, 7]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(sentence.split(\" \")) for sentence in nltk.sent_tokenize(text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Łazik NASA Curiosity zarejestrował na Marsie zjawisko wiru pyłowego, zwane też \"diabłem pyłowym\".\n",
      "Jest częste na Ziemi, tworzy się także na Marsie.\n"
     ]
    }
   ],
   "source": [
    "print(max(nltk.sent_tokenize(text)))\n",
    "print(min(nltk.sent_tokenize(text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_tokens = nltk.sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = [\n",
    "    \"a\", \"aby\", \"ach\", \"acz\", \"aczkolwiek\", \"aj\", \"albo\", \"ale\", \"ależ\", \"ani\", \"aż\", \"bardziej\", \"bardzo\",\n",
    "    \"bez\", \"bo\", \"bowiem\", \"by\", \"byli\", \"bynajmniej\", \"być\", \"był\", \"była\", \"było\", \"były\",\n",
    "    \"będzie\", \"będą\", \"cali\", \"cała\", \"cały\", \"ci\", \"cię\", \"ciebie\", \"co\", \"cokolwiek\", \"coś\", \"czasami\", \"czasem\",\n",
    "    \"czemu\", \"czy\", \"czyli\", \"daleko\", \"dla\", \"dlaczego\", \"dlatego\", \"do\", \"dobrze\", \"dokąd\", \"dość\",\n",
    "    \"dużo\", \"dwa\", \"dwaj\", \"dwie\", \"dwoje\", \"dzisiaj\", \"dziś\", \"gdy\", \"gdyby\", \"gdyż\", \"gdzie\", \"gdziekolwiek\",\n",
    "    \"gdzieś\", \"go\", \"i\", \"ich\", \"ile\", \"im\", \"inna\", \"inne\", \"inny\", \"innych\", \"iż\", \"ja\", \"ją\", \"jak\", \"jakby\",\n",
    "    \"jaki\", \"jakichś\", \"jakie\", \"jakiś\", \"jakiż\", \"jakkolwiek\", \"jako\", \"jakże\", \"je\", \"jeden\", \"jedna\", \"jednak\",\n",
    "    \"jednakże\", \"jedno\", \"jego\", \"jej\", \"jemu\", \"jest\", \"jestem\", \"jeszcze\", \"jeśli\", \"jeżeli\", \"już\", \"kiedy\",\n",
    "    \"kilka\", \"kimś\", \"kto\", \"ktokolwiek\", \"ktoś\", \"która\", \"które\", \"którego\", \"której\", \"który\", \"których\",\n",
    "    \"którym\", \"którymi\", \"któż\", \"ku\", \"lat\", \"lecz\", \"lub\", \"ma\", \"mają\", \"mam\", \"mi\", \"mimo\", \"mnie\", \"mogą\",\n",
    "    \"moim\", \"może\", \"możliwe\", \"mu\", \"na\", \"nad\", \"nam\", \"nami\", \"nas\", \"nasi\", \"nasz\", \"nasza\", \"nasze\",\n",
    "    \"naszego\", \"naszych\", \"natomiast\", \"nawet\", \"nią\", \"nic\", \"nich\", \"nie\", \"niech\", \"niego\", \"niej\", \"niemu\",\n",
    "    \"nigdy\", \"nim\", \"nimi\", \"niż\", \"no\", \"o\", \"obok\", \"od\", \"około\", \"on\", \"ona\", \"one\", \"oni\", \"ono\", \"oraz\",\n",
    "    \"oto\", \"owszem\", \"pan\", \"pana\", \"pani\", \"po\", \"pod\", \"podczas\", \"pomimo\", \"ponieważ\", \"ponownie\", \"poprzez\",\n",
    "    \"poza\", \"prawie\", \"przecież\", \"przed\", \"przede\", \"przedtem\", \"przez\", \"przy\", \"roku\", \"również\", \"sam\",\n",
    "    \"sama\", \"są\", \"się\", \"skąd\", \"sobie\", \"sposób\", \"swoje\", \"ta\", \"tak\", \"taka\", \"taki\", \"takich\", \"takie\",\n",
    "    \"także\", \"tam\", \"te\", \"tego\", \"tej\", \"ten\", \"teraz\", \"też\", \"to\", \"tobą\", \"tobie\", \"toteż\", \"trzeba\",\n",
    "    \"tu\", \"tutaj\", \"twoim\", \"twój\", \"twym\", \"ty\", \"tych\", \"tylko\", \"tym\", \"u\", \"w\", \"we\", \"więc\", \"więcej\",\n",
    "    \"wszyscy\", \"wszystkich\", \"wszystkie\", \"wszystkim\", \"wszystko\", \"wtedy\", \"www\", \"za\", \"zawsze\", \"ze\", \"zł\",\n",
    "    \"znowu\", \"znów\", \"został\", \"żaden\", \"żadna\", \"żadne\", \"żadnych\", \"że\", \"żeby\"\n",
    "]\n",
    "new_text = \" \".join([word for word in text.split(\" \") if word.lower() not in stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tokens = nltk.sent_tokenize(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Łazik NASA Curiosity zarejestrował na Marsie zjawisko wiru pyłowego, zwane też \"diabłem pyłowym\".', 'Wir, który udało się nagrać jest półprzezroczysty, jednak dobrze widoczny w kamerze łazika, badającego krater Gale.', 'Zjawisko powstaje nad suchym obszarem w wyniku silnej konwekcji.', 'Jest częste na Ziemi, tworzy się także na Marsie.', 'Półkula południowa Czerwonej Planety nagrzewa się, szykując na marsjańskie lato.', 'To prowadzi właśnie do konwekcji i wirów.', 'Silne diabły są w stanie wysoko wnosić kurz i piach, tworząc potężne wiry pyłowe.', 'Na Marsie są one jednak krótkotrwałe i dość ograniczone w obserwacji.', 'Pierwszy raz to zjawisko na Czerwonej Planecie odkryto w latach 70.', 'XX w., w trakcie misji sond Viking.']\n",
      "['Łazik NASA Curiosity zarejestrował Marsie zjawisko wiru pyłowego, zwane \"diabłem pyłowym\".', 'Wir, udało nagrać półprzezroczysty, widoczny kamerze łazika, badającego krater Gale.', 'Zjawisko powstaje suchym obszarem wyniku silnej konwekcji.', 'częste Ziemi, tworzy Marsie.', 'Półkula południowa Czerwonej Planety nagrzewa się, szykując marsjańskie lato.', 'prowadzi właśnie konwekcji wirów.', 'Silne diabły stanie wysoko wnosić kurz piach, tworząc potężne wiry pyłowe.', 'Marsie krótkotrwałe ograniczone obserwacji.', 'Pierwszy raz zjawisko Czerwonej Planecie odkryto latach 70.', 'XX w., trakcie misji sond Viking.']\n"
     ]
    }
   ],
   "source": [
    "print(old_tokens)\n",
    "print(new_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ct7diz-2lKJ7"
   },
   "source": [
    "Możemy też użyć bliblioteki do obsługi wyrażeń regularnych, przykłąd użycia poniżej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vz5_1iSS4sNH",
    "outputId": "d4752f0e-faa7-4375-8071-346d092df6b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ma dwa ko\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "s=\"Ala ma dwa koty. \"\n",
    "m=re.search(\"a(.*)t\",s) #jest pomiędzya a i t\n",
    "print(m.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W-p3oIVSlaKQ",
    "outputId": "17e30b04-ca07-46c4-f97f-659f2f7d1d52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la ma dwa ko\n"
     ]
    }
   ],
   "source": [
    "#uwzględniamy mała i wielką literę\n",
    "m=re.match(\"a(.*)t\",s)\n",
    "if m: print(m.group(1))\n",
    "m=re.match(\"A(.*)t\",s)\n",
    "if m: print(m.group(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 2\n",
    "\n",
    "Wracamy do słów jako tokenów.\n",
    "Podziel tekst na tokeny przy użyciu innych narzędzi z pakietu NLTK: \n",
    "\n",
    "* tokenizer oparty o interpunkcje np.print(wordpunct_tokenize(text)\n",
    "* tokenizer oparty o korpus(drzewo) np. TreebankWordTokenizer()\n",
    "* tokenizer dla tweetów : TweetTokenizer()\n",
    "* tokenizer rozpoznajacy związki wyrazowe (Multi-word expression tokenizer, działa po angielsku, ale można spróbowac na polskim) : MWETokenizer()\n",
    " \n",
    "\n",
    "Nie musisz wybierać tych które zostały wymienione, ale tak będzie najłatwiej.\n",
    " \n",
    "  Jest jeden wyjątek!!! Dzisiaj NIE używamy pakietu spacy :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### podpunkty dla chętnych: \n",
    "\n",
    "* tokenizator z bilblioteki Gensim ( dla dużych zbiorów danych) : from gensim.utils import tokenize \n",
    "* tokenizator z biblioteki Keras (from keras.preprocessing.text import Tokenizer ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kod do zadania 2\n",
    "text_zdania=(\"Teraz potrzebuję wiecej niż jedno zdanie. Na przykład dwa. Albo jeszcze lepiej trzy! I dodatkowe z nazwą Counter Strike :-) . A  my favourite prezydent to F.D, Roosvelt, bo ma ciekawe midlle name.\")\n",
    "import nltk \n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Teraz', 'potrzebuję', 'wiecej', 'niż', 'jedno', 'zdanie', '.', 'Na', 'przykład', 'dwa', '.', 'Albo', 'jeszcze', 'lepiej', 'trzy', '!', 'I', 'dodatkowe', 'z', 'nazwą', 'Counter', 'Strike', ':-)', '.', 'A', 'my', 'favourite', 'prezydent', 'to', 'F', '.', 'D', ',', 'Roosvelt', ',', 'bo', 'ma', 'ciekawe', 'midlle', 'name', '.']\n"
     ]
    }
   ],
   "source": [
    "wordpunct = nltk.wordpunct_tokenize(text_zdania)\n",
    "print(wordpunct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Teraz', 'potrzebuję', 'wiecej', 'niż', 'jedno', 'zdanie.', 'Na', 'przykład', 'dwa.', 'Albo', 'jeszcze', 'lepiej', 'trzy', '!', 'I', 'dodatkowe', 'z', 'nazwą', 'Counter', 'Strike', ':', '-', ')', '.', 'A', 'my', 'favourite', 'prezydent', 'to', 'F.D', ',', 'Roosvelt', ',', 'bo', 'ma', 'ciekawe', 'midlle', 'name', '.']\n",
      "Teraz potrzebuję wiecej niż jedno zdanie. Na przykład dwa. Albo jeszcze lepiej trzy! I dodatkowe z nazwą Counter Strike: -). A my favourite prezydent to F.D, Roosvelt, bo ma ciekawe midlle name.\n"
     ]
    }
   ],
   "source": [
    "treebank = nltk.TreebankWordTokenizer().tokenize(text_zdania)\n",
    "print(treebank)\n",
    "\n",
    "detreebank = nltk.TreebankWordDetokenizer().detokenize(treebank)\n",
    "print(detreebank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Teraz', 'potrzebuję', 'wiecej', 'niż', 'jedno', 'zdanie', '.', 'Na', 'przykład', 'dwa', '.', 'Albo', 'jeszcze', 'lepiej', 'trzy', '!', 'I', 'dodatkowe', 'z', 'nazwą', 'Counter', 'Strike', ':-)', '.', 'A', 'my', 'favourite', 'prezydent', 'to', 'F', '.', 'D', ',', 'Roosvelt', ',', 'bo', 'ma', 'ciekawe', 'midlle', 'name', '.']\n"
     ]
    }
   ],
   "source": [
    "tweet = nltk.TweetTokenizer().tokenize(text_zdania)\n",
    "print(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Teraz', 'potrzebuję', 'wiecej', 'niż', 'jedno', 'zdanie.', 'Na', 'przykład', 'dwa.', 'Albo', 'jeszcze', 'lepiej', 'trzy!', 'I', 'dodatkowe', 'z', 'nazwą', 'Counter', 'Strike', ':-)', '.', 'A', 'my', 'favourite', 'prezydent', 'to', 'F.D,', 'Roosvelt,', 'bo', 'ma', 'ciekawe', 'midlle', 'name.']\n",
      "['This', 'is', 'some', 'kind', 'of', 'english', 'sentence']\n"
     ]
    }
   ],
   "source": [
    "mwe = nltk.MWETokenizer().tokenize(text_zdania.split())\n",
    "print(mwe)\n",
    "\n",
    "mwe = nltk.MWETokenizer().tokenize(\"This is some kind of english sentence\".split())\n",
    "print(mwe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'broadcast_to' from 'numpy.lib.stride_tricks' (/Users/mchojna/Documents/Repos/INL/PY_INL/lib/python3.10/site-packages/numpy/lib/stride_tricks.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tokenize\n\u001b[1;32m      2\u001b[0m tok \u001b[38;5;241m=\u001b[39m tokenize(text_zdania)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(tok)\n",
      "File \u001b[0;32m~/Documents/Repos/INL/PY_INL/lib/python3.10/site-packages/gensim/__init__.py:11\u001b[0m\n\u001b[1;32m      7\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4.3.3\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parsing, corpora, matutils, interfaces, models, similarities, utils  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m     14\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgensim\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m logger\u001b[38;5;241m.\u001b[39mhandlers:  \u001b[38;5;66;03m# To ensure reload() doesn't add another one\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Repos/INL/PY_INL/lib/python3.10/site-packages/gensim/parsing/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"This package contains functions to preprocess raw text\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mporter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PorterStemmer  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     preprocess_documents,\n\u001b[1;32m      6\u001b[0m     preprocess_string,\n\u001b[1;32m      7\u001b[0m     read_file,\n\u001b[1;32m      8\u001b[0m     read_files,\n\u001b[1;32m      9\u001b[0m     remove_stopwords,\n\u001b[1;32m     10\u001b[0m     split_alphanum,\n\u001b[1;32m     11\u001b[0m     stem_text,\n\u001b[1;32m     12\u001b[0m     strip_multiple_whitespaces,\n\u001b[1;32m     13\u001b[0m     strip_non_alphanum,\n\u001b[1;32m     14\u001b[0m     strip_numeric,\n\u001b[1;32m     15\u001b[0m     strip_punctuation,\n\u001b[1;32m     16\u001b[0m     strip_short,\n\u001b[1;32m     17\u001b[0m     strip_tags,\n\u001b[1;32m     18\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Repos/INL/PY_INL/lib/python3.10/site-packages/gensim/parsing/preprocessing.py:26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mstring\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mglob\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparsing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mporter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PorterStemmer\n\u001b[1;32m     30\u001b[0m STOPWORDS \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfrozenset\u001b[39m([\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msix\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjust\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mless\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbeing\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindeed\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mover\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmove\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124manyway\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfour\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mown\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthrough\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124musing\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfifty\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhere\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmill\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124monly\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfind\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mone\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhose\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhow\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msomewhere\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmake\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124monce\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     59\u001b[0m ])\n",
      "File \u001b[0;32m~/Documents/Repos/INL/PY_INL/lib/python3.10/site-packages/gensim/utils.py:35\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtypes\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msmart_open\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;28mopen\u001b[39m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m gensim_version\n",
      "File \u001b[0;32m~/Documents/Repos/INL/PY_INL/lib/python3.10/site-packages/scipy/sparse/__init__.py:294\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# Original code by Travis Oliphant.\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;66;03m# Modified and extended by Ed Schofield, Robert Cimrman,\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;66;03m# Nathan Bell, and Jake Vanderplas.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_warnings\u001b[39;00m\n\u001b[0;32m--> 294\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_csr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_csc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Repos/INL/PY_INL/lib/python3.10/site-packages/scipy/sparse/_base.py:5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m warn\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_util\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VisibleDeprecationWarning\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sputils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (asmatrix, check_reshape_kwargs, check_shape,\n\u001b[1;32m      8\u001b[0m                        get_sum_dtype, isdense, isscalarlike,\n\u001b[1;32m      9\u001b[0m                        matrix, validateaxis,)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_matrix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m spmatrix\n",
      "File \u001b[0;32m~/Documents/Repos/INL/PY_INL/lib/python3.10/site-packages/scipy/_lib/_util.py:18\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m     Optional,\n\u001b[1;32m     12\u001b[0m     Union,\n\u001b[1;32m     13\u001b[0m     TYPE_CHECKING,\n\u001b[1;32m     14\u001b[0m     TypeVar,\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_array_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m array_namespace\n\u001b[1;32m     21\u001b[0m AxisError: \u001b[38;5;28mtype\u001b[39m[\u001b[38;5;167;01mException\u001b[39;00m]\n\u001b[1;32m     22\u001b[0m ComplexWarning: \u001b[38;5;28mtype\u001b[39m[\u001b[38;5;167;01mWarning\u001b[39;00m]\n",
      "File \u001b[0;32m~/Documents/Repos/INL/PY_INL/lib/python3.10/site-packages/scipy/_lib/_array_api.py:17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m array_api_compat\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray_api_compat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     18\u001b[0m     is_array_api_obj,\n\u001b[1;32m     19\u001b[0m     size,\n\u001b[1;32m     20\u001b[0m     numpy \u001b[38;5;28;01mas\u001b[39;00m np_compat,\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     23\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marray_namespace\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_asarray\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# To enable array API and strict array-like input validation\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Repos/INL/PY_INL/lib/python3.10/site-packages/scipy/_lib/array_api_compat/numpy/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# from numpy import * doesn't overwrite these builtin names\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;28mabs\u001b[39m, \u001b[38;5;28mmax\u001b[39m, \u001b[38;5;28mmin\u001b[39m, \u001b[38;5;28mround\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Repos/INL/PY_INL/lib/python3.10/site-packages/numpy/__init__.py:346\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    338\u001b[0m     public_symbols -= {\n\u001b[1;32m    339\u001b[0m         \"core\", \"matrixlib\",\n\u001b[1;32m    340\u001b[0m         # These were moved in 1.25 and may be deprecated eventually:\n\u001b[1;32m    341\u001b[0m         \"ModuleDeprecationWarning\", \"VisibleDeprecationWarning\",\n\u001b[1;32m    342\u001b[0m         \"ComplexWarning\", \"TooHardError\", \"AxisError\"\n\u001b[1;32m    343\u001b[0m     }\n\u001b[1;32m    344\u001b[0m     return list(public_symbols)\n\u001b[0;32m--> 346\u001b[0m # Pytest testing\n\u001b[1;32m    347\u001b[0m from numpy._pytesttester import PytestTester\n\u001b[1;32m    348\u001b[0m test = PytestTester(__name__)\n",
      "File \u001b[0;32m~/Documents/Repos/INL/PY_INL/lib/python3.10/site-packages/numpy/ma/__init__.py:42\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m=============\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mMasked Arrays\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m core\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m extras\n",
      "File \u001b[0;32m~/Documents/Repos/INL/PY_INL/lib/python3.10/site-packages/numpy/ma/core.py:37\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ndarray, amax, amin, iscomplexobj, bool_, _NoValue\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m array \u001b[38;5;28;01mas\u001b[39;00m narray\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunction_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m angle\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     39\u001b[0m     getargspec, formatargspec, long, unicode, \u001b[38;5;28mbytes\u001b[39m\n\u001b[1;32m     40\u001b[0m     )\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m expand_dims\n",
      "File \u001b[0;32m~/Documents/Repos/INL/PY_INL/lib/python3.10/site-packages/numpy/lib/function_base.py:25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m overrides\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunction_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m add_newdoc\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtwodim_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m diag\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmultiarray\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     27\u001b[0m     _place, add_docstring, bincount, normalize_axis_index, _monotonicity,\n\u001b[1;32m     28\u001b[0m     interp \u001b[38;5;28;01mas\u001b[39;00m compiled_interp, interp_complex \u001b[38;5;28;01mas\u001b[39;00m compiled_interp_complex\n\u001b[1;32m     29\u001b[0m     )\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mumath\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _add_newdoc_ufunc \u001b[38;5;28;01mas\u001b[39;00m add_newdoc_ufunc\n",
      "File \u001b[0;32m~/Documents/Repos/INL/PY_INL/lib/python3.10/site-packages/numpy/lib/twodim_base.py:15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m overrides\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m iinfo\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstride_tricks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m broadcast_to\n\u001b[1;32m     18\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiag\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiagflat\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meye\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfliplr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflipud\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtri\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtriu\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtril\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvander\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhistogram2d\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask_indices\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtril_indices\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtril_indices_from\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtriu_indices\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtriu_indices_from\u001b[39m\u001b[38;5;124m'\u001b[39m, ]\n\u001b[1;32m     24\u001b[0m array_function_dispatch \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[1;32m     25\u001b[0m     overrides\u001b[38;5;241m.\u001b[39marray_function_dispatch, module\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'broadcast_to' from 'numpy.lib.stride_tricks' (/Users/mchojna/Documents/Repos/INL/PY_INL/lib/python3.10/site-packages/numpy/lib/stride_tricks.py)"
     ]
    }
   ],
   "source": [
    "from gensim.utils import tokenize\n",
    "tok = tokenize(text_zdania)\n",
    "print(tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 2.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "`np.complex_` was removed in the NumPy 2.0 release. Use `np.complex128` instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tokenizer\n\u001b[1;32m      3\u001b[0m tok \u001b[38;5;241m=\u001b[39m Tokenizer()\n",
      "File \u001b[0;32m~/Documents/Repos/INL/PY_INL/lib/python3.10/site-packages/tensorflow/__init__.py:45\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[1;32m     43\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "File \u001b[0;32m~/Documents/Repos/INL/PY_INL/lib/python3.10/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch\n",
      "File \u001b[0;32m~/Documents/Repos/INL/PY_INL/lib/python3.10/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mag_ctx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_convert \u001b[38;5;66;03m# line: 493\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Repos/INL/PY_INL/lib/python3.10/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[1;32m     25\u001b[0m stacks \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mlocal()\n",
      "File \u001b[0;32m~/Documents/Repos/INL/PY_INL/lib/python3.10/site-packages/tensorflow/python/autograph/utils/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext_managers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor_list\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n",
      "File \u001b[0;32m~/Documents/Repos/INL/PY_INL/lib/python3.10/site-packages/tensorflow/python/autograph/utils/context_managers.py:20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcontextlib\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcontrol_dependency_on_returns\u001b[39m(return_value):\n\u001b[1;32m     24\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Create a TF control dependency on the return values of a function.\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m  If the function had no return value, a no-op context is returned.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m    A context manager.\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Repos/INL/PY_INL/lib/python3.10/site-packages/tensorflow/python/ops/tensor_array_ops.py:36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m type_spec\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m type_spec_registry\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m array_ops\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m array_ops_stack\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_flow_util\n",
      "File \u001b[0;32m~/Documents/Repos/INL/PY_INL/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py:22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m flags\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtensor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m api \u001b[38;5;28;01mas\u001b[39;00m d_api\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m record\n",
      "File \u001b[0;32m~/Documents/Repos/INL/PY_INL/lib/python3.10/site-packages/tensorflow/dtensor/python/api.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Optional, Sequence\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtensor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dtensor_device\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtensor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gen_dtensor_ops\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtensor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layout \u001b[38;5;28;01mas\u001b[39;00m layout_lib\n",
      "File \u001b[0;32m~/Documents/Repos/INL/PY_INL/lib/python3.10/site-packages/tensorflow/dtensor/python/dtensor_device.py:33\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dtypes\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sparse_tensor\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_util\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _pywrap_utils\n",
      "File \u001b[0;32m~/Documents/Repos/INL/PY_INL/lib/python3.10/site-packages/tensorflow/python/framework/sparse_tensor.py:28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dtypes\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m override_binary_operator\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_shape\n",
      "File \u001b[0;32m~/Documents/Repos/INL/PY_INL/lib/python3.10/site-packages/tensorflow/python/framework/override_binary_operator.py:24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_shape\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gen_math_ops\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy_ops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m np_dtypes\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nest\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m traceback_utils\n",
      "File \u001b[0;32m~/Documents/Repos/INL/PY_INL/lib/python3.10/site-packages/tensorflow/python/ops/numpy_ops/np_dtypes.py:30\u001b[0m\n\u001b[1;32m     26\u001b[0m bool_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbool_\n\u001b[1;32m     27\u001b[0m tf_export\u001b[38;5;241m.\u001b[39mtf_export(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexperimental.numpy.bool_\u001b[39m\u001b[38;5;124m'\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\u001b[38;5;241m.\u001b[39mexport_constant(\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbool_\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     29\u001b[0m )\n\u001b[0;32m---> 30\u001b[0m complex_ \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomplex_\u001b[49m\n\u001b[1;32m     31\u001b[0m tf_export\u001b[38;5;241m.\u001b[39mtf_export(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexperimental.numpy.complex_\u001b[39m\u001b[38;5;124m'\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\u001b[38;5;241m.\u001b[39mexport_constant(\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomplex_\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     34\u001b[0m complex128 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcomplex128\n",
      "File \u001b[0;32m~/Documents/Repos/INL/PY_INL/lib/python3.10/site-packages/numpy/__init__.py:400\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _wn\u001b[38;5;241m.\u001b[39mcategory \u001b[38;5;129;01mis\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mRankWarning:\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;66;03m# Ignore other warnings, they may not be relevant (see gh-25433).\u001b[39;00m\n\u001b[1;32m    399\u001b[0m         error_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_wn\u001b[38;5;241m.\u001b[39mcategory\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(_wn\u001b[38;5;241m.\u001b[39mmessage)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 400\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    401\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPolyfit sanity test emitted a warning, most likely due \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto using a buggy Accelerate backend.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf you compiled yourself, more information is available at:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    404\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mhttps://numpy.org/devdocs/building/index.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    405\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mOtherwise report this to the vendor \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    406\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthat provided NumPy.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(error_message))\n\u001b[1;32m    407\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg)\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _wn\n",
      "\u001b[0;31mAttributeError\u001b[0m: `np.complex_` was removed in the NumPy 2.0 release. Use `np.complex128` instead."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tf.keras.preprocessing.text import Tokenizer\n",
    "tok = Tokenizer()\n",
    "print(tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 3\n",
    "\n",
    "Poszukaj w dokumentacji charakterystyki działania każdego z użtych tokenizatorów i wymyśl dla jednego z nich zdanie którego nie  podzieli poprawnie. \n",
    "\n",
    "Napisz kod który zilustruje błędny podział.\n",
    "\n",
    "Uzasadnij (komentarzami w kodzie) czemu właśnie takie zdanie zostało wybrane.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"I can't believe it's already 3:30pm!\"\n",
    "# dzieli tekst na slowa i znaki interpunkcyjne jako oddzielne tokeny\n",
    "tokens = nltk.WordPunctTokenizer().tokenize(sentence)\n",
    "print(tokens)\n",
    "\n",
    "# rozdziela skroty z apostrofem (np. \"can't\" -> [\"can\", \"'\", \"t\"]), co jest niepoprawne\n",
    "# rozdziela \"it's\" na [\"it\", \"'\", \"s\"], co jest niepoprawne\n",
    "# niepoprawnie rozbija \"3:30pm\" na [\"3\", \":\", \"30pm\"]\n",
    "# powinien traktowac \"3:30pm\" jako jeden token, ale separator \":\" jest traktowany jako osobny token,\n",
    "# co skutkuje blednym podziałem czasu na liczby i koncowke \"pm\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yRTWJYdd3Rs1"
   },
   "source": [
    "# Zadanie 4 (cool down)\n",
    "Napisz (można komentarzami) co robi poniższy kod\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 633
    },
    "id": "KQCYfOQHm8US",
    "outputId": "640e6284-d4bf-4bd9-82d5-a5c19f063feb"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import udhr\n",
    "import matplotlib.pyplot as plot\n",
    "print(udhr.fileids())\n",
    "up=udhr.words('Polish_Polski-Latin2') \n",
    "print(up[:100])\n",
    "fqup=nltk.FreqDist(up) \n",
    "fqup.plot(30)\n",
    "v=fqup.keys()\n",
    "\n",
    "pnum_chars = len(udhr.raw('Polish_Polski-Latin2'))\n",
    "pnum_words = len(udhr.words('Polish_Polski-Latin2'))\n",
    "pnum_sents = len(udhr.sents('Polish_Polski-Latin2')) \n",
    "print (\"?\", pnum_chars, \"?\", pnum_words, \"?\", pnum_sents) \n",
    "print(\"?\", int(pnum_chars/pnum_words))\n",
    "print( \"?\", int(pnum_words/pnum_sents))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "PY_INL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
