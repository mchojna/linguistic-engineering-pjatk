{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32s2BT904GEe"
   },
   "source": [
    "# Ćwiczenia 2\n",
    "\n",
    "Ponownie zaimportuj pakiet nltk (natural language toolkit)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3aqFlDVd4OLl"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/mchojna/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Error loading stop: Package 'stop' not found in index\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mchojna/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pip install nltk\n",
    "#w colabie zbędne\n",
    "import nltk\n",
    "# nltk.download() \n",
    "nltk.download('punkt')\n",
    "nltk.download('stop')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m22byVdnsMQZ"
   },
   "source": [
    "# Tokenizacja na większe części\n",
    "\n",
    "Teraz podzielmy tekst na zdania.\n",
    "\n",
    "Każdy pakiet ma zaszyty sposób podziału, na przykład to czy kropka wchodzi w zdanie czy nie, czy spacja przed czy po, a może w ogóle bez.\n",
    "\n",
    "Te decyzje wydaja się błahe ale niewłaściwy podział może bardzo przeszkadzać w  dalszej pracy z tekstem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1P6Tzi-8sSZc",
    "outputId": "52a224f4-7a96-4474-b386-48d17198abf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Podział na zdania prezentuje się tak:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Teraz potrzebuję wiecej niż jedno zdanie.',\n",
       " 'Na przykład dwa.',\n",
       " 'Albo jeszcze lepiej trzy!']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_zdania=(\"Teraz potrzebuję wiecej niż jedno zdanie. Na przykład dwa. Albo jeszcze lepiej trzy!\")\n",
    "print(\"Podział na zdania prezentuje się tak:\")\n",
    "nltk.sent_tokenize(text_zdania)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bvQlo_Pgsrl0"
   },
   "source": [
    "# Zadanie 1\n",
    "> 'Łazik NASA Curiosity zarejestrował na Marsie zjawisko wiru pyłowego, zwane też \"diabłem pyłowym\". Wir, który udało się nagrać jest półprzezroczysty, jednak dobrze widoczny w kamerze łazika, badającego krater Gale. Zjawisko powstaje nad suchym obszarem w wyniku silnej konwekcji. Jest częste na Ziemi, tworzy się także na Marsie. Półkula południowa Czerwonej Planety nagrzewa się, szykując na marsjańskie lato. To prowadzi właśnie do konwekcji i wirów. Silne diabły są w stanie wysoko wnosić kurz i piach, tworząc potężne wiry pyłowe. Na Marsie są one jednak krótkotrwałe i dość ograniczone w obserwacji. Pierwszy raz to zjawisko na Czerwonej Planecie odkryto w latach 70. XX w., w trakcie misji sond Viking.'\n",
    "\n",
    "* Tekst podzielić na zdania. \n",
    "\n",
    "* Policzyć wyrazy w kazdym zdaniu\n",
    "\n",
    "* Wyświetlić najkrótsze i najdłuższe zdanie\n",
    "\n",
    "* Porównać wynik przed i po eliminacji stopwordsów (można uzyc dowolnej listy) oraz po usunięciu interpunkcji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2rUMFXcJuaPy"
   },
   "outputs": [],
   "source": [
    "#kod do zadania 1\n",
    "text = 'Łazik NASA Curiosity zarejestrował na Marsie zjawisko wiru pyłowego, zwane też \"diabłem pyłowym\". Wir, który udało się nagrać jest półprzezroczysty, jednak dobrze widoczny w kamerze łazika, badającego krater Gale. Zjawisko powstaje nad suchym obszarem w wyniku silnej konwekcji. Jest częste na Ziemi, tworzy się także na Marsie. Półkula południowa Czerwonej Planety nagrzewa się, szykując na marsjańskie lato. To prowadzi właśnie do konwekcji i wirów. Silne diabły są w stanie wysoko wnosić kurz i piach, tworząc potężne wiry pyłowe. Na Marsie są one jednak krótkotrwałe i dość ograniczone w obserwacji. Pierwszy raz to zjawisko na Czerwonej Planecie odkryto w latach 70. XX w., w trakcie misji sond Viking.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Łazik NASA Curiosity zarejestrował na Marsie zjawisko wiru pyłowego, zwane też \"diabłem pyłowym\".',\n",
       " 'Wir, który udało się nagrać jest półprzezroczysty, jednak dobrze widoczny w kamerze łazika, badającego krater Gale.',\n",
       " 'Zjawisko powstaje nad suchym obszarem w wyniku silnej konwekcji.',\n",
       " 'Jest częste na Ziemi, tworzy się także na Marsie.',\n",
       " 'Półkula południowa Czerwonej Planety nagrzewa się, szykując na marsjańskie lato.',\n",
       " 'To prowadzi właśnie do konwekcji i wirów.',\n",
       " 'Silne diabły są w stanie wysoko wnosić kurz i piach, tworząc potężne wiry pyłowe.',\n",
       " 'Na Marsie są one jednak krótkotrwałe i dość ograniczone w obserwacji.',\n",
       " 'Pierwszy raz to zjawisko na Czerwonej Planecie odkryto w latach 70.',\n",
       " 'XX w., w trakcie misji sond Viking.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "16\n",
      "9\n",
      "9\n",
      "10\n",
      "7\n",
      "14\n",
      "11\n",
      "11\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "for sentence in nltk.sent_tokenize(text):\n",
    "    print(len(sentence.split(\" \")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Łazik NASA Curiosity zarejestrował na Marsie zjawisko wiru pyłowego, zwane też \"diabłem pyłowym\".\n",
      "Jest częste na Ziemi, tworzy się także na Marsie.\n"
     ]
    }
   ],
   "source": [
    "print(max(nltk.sent_tokenize(text)))\n",
    "print(min(nltk.sent_tokenize(text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_tokens = nltk.sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = [\n",
    "    \"a\", \"aby\", \"ach\", \"acz\", \"aczkolwiek\", \"aj\", \"albo\", \"ale\", \"ależ\", \"ani\", \"aż\", \"bardziej\", \"bardzo\",\n",
    "    \"bez\", \"bo\", \"bowiem\", \"by\", \"byli\", \"bynajmniej\", \"być\", \"był\", \"była\", \"było\", \"były\",\n",
    "    \"będzie\", \"będą\", \"cali\", \"cała\", \"cały\", \"ci\", \"cię\", \"ciebie\", \"co\", \"cokolwiek\", \"coś\", \"czasami\", \"czasem\",\n",
    "    \"czemu\", \"czy\", \"czyli\", \"daleko\", \"dla\", \"dlaczego\", \"dlatego\", \"do\", \"dobrze\", \"dokąd\", \"dość\",\n",
    "    \"dużo\", \"dwa\", \"dwaj\", \"dwie\", \"dwoje\", \"dzisiaj\", \"dziś\", \"gdy\", \"gdyby\", \"gdyż\", \"gdzie\", \"gdziekolwiek\",\n",
    "    \"gdzieś\", \"go\", \"i\", \"ich\", \"ile\", \"im\", \"inna\", \"inne\", \"inny\", \"innych\", \"iż\", \"ja\", \"ją\", \"jak\", \"jakby\",\n",
    "    \"jaki\", \"jakichś\", \"jakie\", \"jakiś\", \"jakiż\", \"jakkolwiek\", \"jako\", \"jakże\", \"je\", \"jeden\", \"jedna\", \"jednak\",\n",
    "    \"jednakże\", \"jedno\", \"jego\", \"jej\", \"jemu\", \"jest\", \"jestem\", \"jeszcze\", \"jeśli\", \"jeżeli\", \"już\", \"kiedy\",\n",
    "    \"kilka\", \"kimś\", \"kto\", \"ktokolwiek\", \"ktoś\", \"która\", \"które\", \"którego\", \"której\", \"który\", \"których\",\n",
    "    \"którym\", \"którymi\", \"któż\", \"ku\", \"lat\", \"lecz\", \"lub\", \"ma\", \"mają\", \"mam\", \"mi\", \"mimo\", \"mnie\", \"mogą\",\n",
    "    \"moim\", \"może\", \"możliwe\", \"mu\", \"na\", \"nad\", \"nam\", \"nami\", \"nas\", \"nasi\", \"nasz\", \"nasza\", \"nasze\",\n",
    "    \"naszego\", \"naszych\", \"natomiast\", \"nawet\", \"nią\", \"nic\", \"nich\", \"nie\", \"niech\", \"niego\", \"niej\", \"niemu\",\n",
    "    \"nigdy\", \"nim\", \"nimi\", \"niż\", \"no\", \"o\", \"obok\", \"od\", \"około\", \"on\", \"ona\", \"one\", \"oni\", \"ono\", \"oraz\",\n",
    "    \"oto\", \"owszem\", \"pan\", \"pana\", \"pani\", \"po\", \"pod\", \"podczas\", \"pomimo\", \"ponieważ\", \"ponownie\", \"poprzez\",\n",
    "    \"poza\", \"prawie\", \"przecież\", \"przed\", \"przede\", \"przedtem\", \"przez\", \"przy\", \"roku\", \"również\", \"sam\",\n",
    "    \"sama\", \"są\", \"się\", \"skąd\", \"sobie\", \"sposób\", \"swoje\", \"ta\", \"tak\", \"taka\", \"taki\", \"takich\", \"takie\",\n",
    "    \"także\", \"tam\", \"te\", \"tego\", \"tej\", \"ten\", \"teraz\", \"też\", \"to\", \"tobą\", \"tobie\", \"toteż\", \"trzeba\",\n",
    "    \"tu\", \"tutaj\", \"twoim\", \"twój\", \"twym\", \"ty\", \"tych\", \"tylko\", \"tym\", \"u\", \"w\", \"we\", \"więc\", \"więcej\",\n",
    "    \"wszyscy\", \"wszystkich\", \"wszystkie\", \"wszystkim\", \"wszystko\", \"wtedy\", \"www\", \"za\", \"zawsze\", \"ze\", \"zł\",\n",
    "    \"znowu\", \"znów\", \"został\", \"żaden\", \"żadna\", \"żadne\", \"żadnych\", \"że\", \"żeby\"\n",
    "]\n",
    "new_text = \" \".join([word for word in text.split(\" \") if word.lower() not in stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tokens = nltk.sent_tokenize(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Łazik NASA Curiosity zarejestrował na Marsie zjawisko wiru pyłowego, zwane też \"diabłem pyłowym\".', 'Wir, który udało się nagrać jest półprzezroczysty, jednak dobrze widoczny w kamerze łazika, badającego krater Gale.', 'Zjawisko powstaje nad suchym obszarem w wyniku silnej konwekcji.', 'Jest częste na Ziemi, tworzy się także na Marsie.', 'Półkula południowa Czerwonej Planety nagrzewa się, szykując na marsjańskie lato.', 'To prowadzi właśnie do konwekcji i wirów.', 'Silne diabły są w stanie wysoko wnosić kurz i piach, tworząc potężne wiry pyłowe.', 'Na Marsie są one jednak krótkotrwałe i dość ograniczone w obserwacji.', 'Pierwszy raz to zjawisko na Czerwonej Planecie odkryto w latach 70.', 'XX w., w trakcie misji sond Viking.']\n",
      "['Łazik NASA Curiosity zarejestrował Marsie zjawisko wiru pyłowego, zwane \"diabłem pyłowym\".', 'Wir, udało nagrać półprzezroczysty, widoczny kamerze łazika, badającego krater Gale.', 'Zjawisko powstaje suchym obszarem wyniku silnej konwekcji.', 'częste Ziemi, tworzy Marsie.', 'Półkula południowa Czerwonej Planety nagrzewa się, szykując marsjańskie lato.', 'prowadzi właśnie konwekcji wirów.', 'Silne diabły stanie wysoko wnosić kurz piach, tworząc potężne wiry pyłowe.', 'Marsie krótkotrwałe ograniczone obserwacji.', 'Pierwszy raz zjawisko Czerwonej Planecie odkryto latach 70.', 'XX w., trakcie misji sond Viking.']\n"
     ]
    }
   ],
   "source": [
    "print(old_tokens)\n",
    "print(new_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ct7diz-2lKJ7"
   },
   "source": [
    "Możemy też użyć bliblioteki do obsługi wyrażeń regularnych, przykłąd użycia poniżej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vz5_1iSS4sNH",
    "outputId": "d4752f0e-faa7-4375-8071-346d092df6b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ma dwa ko\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "s=\"Ala ma dwa koty. \"\n",
    "m=re.search(\"a(.*)t\",s) #jest pomiędzya a i t\n",
    "print(m.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W-p3oIVSlaKQ",
    "outputId": "17e30b04-ca07-46c4-f97f-659f2f7d1d52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la ma dwa ko\n"
     ]
    }
   ],
   "source": [
    "#uwzględniamy mała i wielką literę\n",
    "m=re.match(\"a(.*)t\",s)\n",
    "if m: print(m.group(1))\n",
    "m=re.match(\"A(.*)t\",s)\n",
    "if m: print(m.group(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 2\n",
    "\n",
    "Wracamy do słów jako tokenów.\n",
    "Podziel tekst na tokeny przy użyciu innych narzędzi z pakietu NLTK: \n",
    "\n",
    "* tokenizer oparty o interpunkcje np.print(wordpunct_tokenize(text)\n",
    "* tokenizer oparty o korpus(drzewo) np. TreebankWordTokenizer()\n",
    "* tokenizer dla tweetów : TweetTokenizer()\n",
    "* tokenizer rozpoznajacy związki wyrazowe (Multi-word expression tokenizer, działa po angielsku, ale można spróbowac na polskim) : MWETokenizer()\n",
    " \n",
    "\n",
    "Nie musisz wybierać tych które zostały wymienione, ale tak będzie najłatwiej.\n",
    " \n",
    "  Jest jeden wyjątek!!! Dzisiaj NIE używamy pakietu spacy :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### podpunkty dla chętnych: \n",
    "\n",
    "* tokenizator z bilblioteki Gensim ( dla dużych zbiorów danych) : from gensim.utils import tokenize \n",
    "* tokenizator z biblioteki Keras (from keras.preprocessing.text import Tokenizer ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kod do zadania 2\n",
    "text_zdania=(\"Teraz potrzebuję wiecej niż jedno zdanie. Na przykład dwa. Albo jeszcze lepiej trzy! I dodatkowe z nazwą Counter Strike :-) . A  my favourite prezydent to F.D, Roosvelt, bo ma ciekawe midlle name.\")\n",
    "import nltk \n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Teraz', 'potrzebuję', 'wiecej', 'niż', 'jedno', 'zdanie', '.', 'Na', 'przykład', 'dwa', '.', 'Albo', 'jeszcze', 'lepiej', 'trzy', '!', 'I', 'dodatkowe', 'z', 'nazwą', 'Counter', 'Strike', ':-)', '.', 'A', 'my', 'favourite', 'prezydent', 'to', 'F', '.', 'D', ',', 'Roosvelt', ',', 'bo', 'ma', 'ciekawe', 'midlle', 'name', '.']\n"
     ]
    }
   ],
   "source": [
    "wordpunct = nltk.wordpunct_tokenize(text_zdania)\n",
    "print(wordpunct) # jedzie ze wszystkim "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Teraz', 'potrzebuję', 'wiecej', 'niż', 'jedno', 'zdanie.', 'Na', 'przykład', 'dwa.', 'Albo', 'jeszcze', 'lepiej', 'trzy', '!', 'I', 'dodatkowe', 'z', 'nazwą', 'Counter', 'Strike', ':', '-', ')', '.', 'A', 'my', 'favourite', 'prezydent', 'to', 'F.D', ',', 'Roosvelt', ',', 'bo', 'ma', 'ciekawe', 'midlle', 'name', '.']\n",
      "Teraz potrzebuję wiecej niż jedno zdanie. Na przykład dwa. Albo jeszcze lepiej trzy! I dodatkowe z nazwą Counter Strike: -). A my favourite prezydent to F.D, Roosvelt, bo ma ciekawe midlle name.\n"
     ]
    }
   ],
   "source": [
    "treebank = nltk.TreebankWordTokenizer().tokenize(text_zdania)\n",
    "print(treebank) # nie rozdzilil F.D jako inicjalu\n",
    "\n",
    "detreebank = nltk.TreebankWordDetokenizer().detokenize(treebank)\n",
    "print(detreebank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Teraz', 'potrzebuję', 'wiecej', 'niż', 'jedno', 'zdanie', '.', 'Na', 'przykład', 'dwa', '.', 'Albo', 'jeszcze', 'lepiej', 'trzy', '!', 'I', 'dodatkowe', 'z', 'nazwą', 'Counter', 'Strike', ':-)', '.', 'A', 'my', 'favourite', 'prezydent', 'to', 'F', '.', 'D', ',', 'Roosvelt', ',', 'bo', 'ma', 'ciekawe', 'midlle', 'name', '.']\n"
     ]
    }
   ],
   "source": [
    "tweet = nltk.TweetTokenizer().tokenize(text_zdania)\n",
    "print(tweet) # dziala dla emotek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Teraz', 'potrzebuję', 'wiecej', 'niż', 'jedno', 'zdanie.', 'Na', 'przykład', 'dwa.', 'Albo', 'jeszcze', 'lepiej', 'trzy!', 'I', 'dodatkowe', 'z', 'nazwą', 'Counter', 'Strike', ':-)', '.', 'A', 'my', 'favourite', 'prezydent', 'to', 'F.D,', 'Roosvelt,', 'bo', 'ma', 'ciekawe', 'midlle', 'name.']\n",
      "['This', 'is', 'some', 'kind', 'of', 'english', 'sentence']\n"
     ]
    }
   ],
   "source": [
    "mwe = nltk.MWETokenizer().tokenize(text_zdania.split())\n",
    "print(mwe)\n",
    "\n",
    "mwe = nltk.MWETokenizer().tokenize(\"This is some kind of english sentence\".split())\n",
    "print(mwe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Using cached gensim-4.3.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (8.1 kB)\n",
      "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
      "  Using cached numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
      "  Using cached scipy-1.13.1-cp312-cp312-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Using cached smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting wrapt (from smart-open>=1.8.1->gensim)\n",
      "  Using cached wrapt-1.17.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Downloading gensim-4.3.3-cp312-cp312-macosx_11_0_arm64.whl (24.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl (13.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading scipy-1.13.1-cp312-cp312-macosx_12_0_arm64.whl (30.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.4/30.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Downloading wrapt-1.17.2-cp312-cp312-macosx_11_0_arm64.whl (38 kB)\n",
      "Installing collected packages: wrapt, numpy, smart-open, scipy, gensim\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.3\n",
      "    Uninstalling numpy-2.2.3:\n",
      "      Successfully uninstalled numpy-2.2.3\n",
      "Successfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1 smart-open-7.1.0 wrapt-1.17.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (24.2)\n",
      "Collecting pip\n",
      "  Using cached pip-25.0.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Using cached pip-25.0.1-py3-none-any.whl (1.8 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.2\n",
      "    Uninstalling pip-24.2:\n",
      "      Successfully uninstalled pip-24.2\n",
      "Successfully installed pip-25.0.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[78]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tokenize\n\u001b[32m      2\u001b[39m tok = tokenize(text_zdania)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(tok)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages/gensim/__init__.py:11\u001b[39m\n\u001b[32m      7\u001b[39m __version__ = \u001b[33m'\u001b[39m\u001b[33m4.3.3\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parsing, corpora, matutils, interfaces, models, similarities, utils  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[32m     14\u001b[39m logger = logging.getLogger(\u001b[33m'\u001b[39m\u001b[33mgensim\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m logger.handlers:  \u001b[38;5;66;03m# To ensure reload() doesn't add another one\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages/gensim/corpora/__init__.py:6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mThis package contains implementations of various streaming corpus I/O format.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# bring corpus classes directly into package namespace, to save some typing\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mindexedcorpus\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IndexedCorpus  \u001b[38;5;66;03m# noqa:F401 must appear before the other classes\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmmcorpus\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MmCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbleicorpus\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BleiCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages/gensim/corpora/indexedcorpus.py:14\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m interfaces, utils\n\u001b[32m     16\u001b[39m logger = logging.getLogger(\u001b[34m__name__\u001b[39m)\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIndexedCorpus\u001b[39;00m(interfaces.CorpusABC):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages/gensim/interfaces.py:19\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[33;03m\"\"\"Basic interfaces used across the whole Gensim package.\u001b[39;00m\n\u001b[32m      8\u001b[39m \n\u001b[32m      9\u001b[39m \u001b[33;03mThese interfaces are used for building corpora, model transformation and similarity queries.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m \n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m utils, matutils\n\u001b[32m     22\u001b[39m logger = logging.getLogger(\u001b[34m__name__\u001b[39m)\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mCorpusABC\u001b[39;00m(utils.SaveLoad):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages/gensim/matutils.py:1034\u001b[39m\n\u001b[32m   1029\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m1.\u001b[39m - \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mlen\u001b[39m(set1 & set2)) / \u001b[38;5;28mfloat\u001b[39m(union_cardinality)\n\u001b[32m   1032\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1033\u001b[39m     \u001b[38;5;66;03m# try to load fast, cythonized code if possible\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1034\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_matutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m logsumexp, mean_absolute_difference, dirichlet_expectation\n\u001b[32m   1036\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m   1037\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlogsumexp\u001b[39m(x):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages/gensim/_matutils.pyx:1\u001b[39m, in \u001b[36minit gensim._matutils\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "from gensim.utils import tokenize\n",
    "tok = tokenize(text_zdania)\n",
    "print(tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 2.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading keras-3.9.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting absl-py (from keras)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: numpy in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from keras) (1.26.4)\n",
      "Collecting rich (from keras)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting h5py (from keras)\n",
      "  Downloading h5py-3.13.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.5 kB)\n",
      "Collecting optree (from keras)\n",
      "  Downloading optree-0.14.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (49 kB)\n",
      "Collecting ml-dtypes (from keras)\n",
      "  Downloading ml_dtypes-0.5.1-cp312-cp312-macosx_10_9_universal2.whl.metadata (21 kB)\n",
      "Requirement already satisfied: packaging in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from keras) (24.2)\n",
      "Collecting typing-extensions>=4.5.0 (from optree->keras)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from rich->keras) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading keras-3.9.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m504.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading h5py-3.13.0-cp312-cp312-macosx_11_0_arm64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.1-cp312-cp312-macosx_10_9_universal2.whl (670 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.4/670.4 kB\u001b[0m \u001b[31m901.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.14.1-cp312-cp312-macosx_11_0_arm64.whl (339 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, typing-extensions, ml-dtypes, mdurl, h5py, absl-py, optree, markdown-it-py, rich, keras\n",
      "Successfully installed absl-py-2.1.0 h5py-3.13.0 keras-3.9.0 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.5.1 namex-0.0.8 optree-0.14.1 rich-13.9.4 typing-extensions-4.12.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from tensorflow) (24.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Downloading protobuf-5.29.3-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Collecting requests<3,>=2.21.0 (from tensorflow)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting setuptools (from tensorflow)\n",
      "  Downloading setuptools-76.0.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from tensorflow) (1.17.2)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.71.0-cp312-cp312-macosx_10_14_universal2.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: keras>=3.5.0 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from tensorflow) (3.13.0)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp312-cp312-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: rich in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached charset_normalizer-3.4.1-cp312-cp312-macosx_10_13_universal2.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading MarkupSafe-3.0.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Downloading tensorflow-2.18.0-cp312-cp312-macosx_12_0_arm64.whl (239.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.6/239.6 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0mm\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.71.0-cp312-cp312-macosx_10_14_universal2.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl (25.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.8/25.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.4.1-cp312-cp312-macosx_10_9_universal2.whl (405 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-5.29.3-cp38-abi3-macosx_10_9_universal2.whl (417 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading setuptools-76.0.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp312-cp312-macosx_10_13_universal2.whl (196 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp312-cp312-macosx_11_0_arm64.whl (12 kB)\n",
      "Installing collected packages: libclang, flatbuffers, wheel, urllib3, termcolor, tensorboard-data-server, setuptools, protobuf, opt-einsum, ml-dtypes, MarkupSafe, markdown, idna, grpcio, google-pasta, gast, charset-normalizer, certifi, werkzeug, requests, astunparse, tensorboard, tensorflow\n",
      "  Attempting uninstall: ml-dtypes\n",
      "    Found existing installation: ml_dtypes 0.5.1\n",
      "    Uninstalling ml_dtypes-0.5.1:\n",
      "      Successfully uninstalled ml_dtypes-0.5.1\n",
      "Successfully installed MarkupSafe-3.0.2 astunparse-1.6.3 certifi-2025.1.31 charset-normalizer-3.4.1 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.71.0 idna-3.10 libclang-18.1.1 markdown-3.7 ml-dtypes-0.4.1 opt-einsum-3.4.0 protobuf-5.29.3 requests-2.32.3 setuptools-76.0.0 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 termcolor-2.5.0 urllib3-2.3.0 werkzeug-3.1.3 wheel-0.45.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-macos\n",
      "  Downloading tensorflow_macos-2.16.2-cp312-cp312-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow==2.16.2 (from tensorflow-macos)\n",
      "  Downloading tensorflow-2.16.2-cp312-cp312-macosx_12_0_arm64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (3.13.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (18.1.1)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading ml_dtypes-0.3.2-cp312-cp312-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (24.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading protobuf-4.25.6-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (76.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (1.71.0)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: keras>=3.0.0 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (3.9.0)\n",
      "Collecting numpy<2.0.0,>=1.26.0 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Using cached numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow==2.16.2->tensorflow-macos) (0.45.1)\n",
      "Requirement already satisfied: rich in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos) (13.9.4)\n",
      "Requirement already satisfied: namex in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos) (0.0.8)\n",
      "Requirement already satisfied: optree in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos) (0.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow-macos) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow-macos) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow-macos) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow-macos) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos) (0.1.2)\n",
      "Downloading tensorflow_macos-2.16.2-cp312-cp312-macosx_12_0_arm64.whl (2.1 kB)\n",
      "Downloading tensorflow-2.16.2-cp312-cp312-macosx_12_0_arm64.whl (227.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.3.2-cp312-cp312-macosx_10_9_universal2.whl (393 kB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl (13.7 MB)\n",
      "Downloading protobuf-4.25.6-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hInstalling collected packages: protobuf, numpy, tensorboard, ml-dtypes, tensorflow, tensorflow-macos\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 5.29.3\n",
      "    Uninstalling protobuf-5.29.3:\n",
      "      Successfully uninstalled protobuf-5.29.3\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.3\n",
      "    Uninstalling numpy-2.2.3:\n",
      "      Successfully uninstalled numpy-2.2.3\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.18.0\n",
      "    Uninstalling tensorboard-2.18.0:\n",
      "      Successfully uninstalled tensorboard-2.18.0\n",
      "  Attempting uninstall: ml-dtypes\n",
      "    Found existing installation: ml-dtypes 0.4.1\n",
      "    Uninstalling ml-dtypes-0.4.1:\n",
      "      Successfully uninstalled ml-dtypes-0.4.1\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.18.0\n",
      "    Uninstalling tensorflow-2.18.0:\n",
      "      Successfully uninstalled tensorflow-2.18.0\n",
      "Successfully installed ml-dtypes-0.3.2 numpy-1.26.4 protobuf-4.25.6 tensorboard-2.16.2 tensorflow-2.16.2 tensorflow-macos-2.16.2\n"
     ]
    }
   ],
   "source": [
    "# !pip install tensorflow-macos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-metal\n",
      "  Downloading tensorflow_metal-1.2.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: wheel~=0.35 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from tensorflow-metal) (0.45.1)\n",
      "Requirement already satisfied: six>=1.15.0 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from tensorflow-metal) (1.17.0)\n",
      "Downloading tensorflow_metal-1.2.0-cp312-cp312-macosx_12_0_arm64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tensorflow-metal\n",
      "Successfully installed tensorflow-metal-1.2.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install tensorflow-metal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement distutils (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for distutils\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip install distutils\n",
    "# The last version of Python that provided the distutils module was Python 3.11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'distutils'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[85]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tokenizer\n\u001b[32m      3\u001b[39m tok = Tokenizer()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages/tensorflow/__init__.py:30\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[33;03mTop-level module of TensorFlow. By convention, we refer to this module as\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[33;03m`tf` instead of `tensorflow`, following the common practice of importing\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     26\u001b[39m \u001b[33;03mthis file with a file generated from [`api_template.__init__.py`](https://www.github.com/tensorflow/tensorflow/blob/master/tensorflow/api_template.__init__.py)\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# pylint: disable=g-bad-import-order,protected-access,g-import-not-at-top\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdistutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m_distutils\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimportlib\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minspect\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m_inspect\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'distutils'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tf.keras.preprocessing.text import Tokenizer\n",
    "tok = Tokenizer()\n",
    "print(tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 3\n",
    "\n",
    "Poszukaj w dokumentacji charakterystyki działania każdego z użtych tokenizatorów i wymyśl dla jednego z nich zdanie którego nie  podzieli poprawnie. \n",
    "\n",
    "Napisz kod który zilustruje błędny podział.\n",
    "\n",
    "Uzasadnij (komentarzami w kodzie) czemu właśnie takie zdanie zostało wybrane.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'can', \"'\", 't', 'believe', 'it', \"'\", 's', 'already', '3', ':', '30pm', '!']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I can't believe it's already 3:30pm!\"\n",
    "# dzieli tekst na slowa i znaki interpunkcyjne jako oddzielne tokeny\n",
    "tokens = nltk.WordPunctTokenizer().tokenize(sentence)\n",
    "print(tokens)\n",
    "\n",
    "# rozdziela skroty z apostrofem (np. \"can't\" -> [\"can\", \"'\", \"t\"]), co jest niepoprawne\n",
    "# rozdziela \"it's\" na [\"it\", \"'\", \"s\"], co jest niepoprawne\n",
    "# niepoprawnie rozbija \"3:30pm\" na [\"3\", \":\", \"30pm\"]\n",
    "# powinien traktowac \"3:30pm\" jako jeden token, ale separator \":\" jest traktowany jako osobny token,\n",
    "# co skutkuje blednym podziałem czasu na liczby i koncowke \"pm\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yRTWJYdd3Rs1"
   },
   "source": [
    "# Zadanie 4 (cool down)\n",
    "Napisz (można komentarzami) co robi poniższy kod\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 633
    },
    "id": "KQCYfOQHm8US",
    "outputId": "640e6284-d4bf-4bd9-82d5-a5c19f063feb"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute 'rcParams'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[77]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcorpus\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m udhr\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplot\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(udhr.fileids())\n\u001b[32m      4\u001b[39m up=udhr.words(\u001b[33m'\u001b[39m\u001b[33mPolish_Polski-Latin2\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages/matplotlib/pyplot.py:57\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcycler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cycler  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolorbar\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _api\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages/matplotlib/colorbar.py:19\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmpl\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _api, cbook, collections, cm, colors, contour, ticker\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01martist\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmartist\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpatches\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmpatches\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages/matplotlib/collections.py:21\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmpl\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (_api, _path, artist, cbook, colorizer \u001b[38;5;28;01mas\u001b[39;00m mcolorizer, colors \u001b[38;5;28;01mas\u001b[39;00m mcolors,\n\u001b[32m     22\u001b[39m                _docstring, hatch \u001b[38;5;28;01mas\u001b[39;00m mhatch, lines \u001b[38;5;28;01mas\u001b[39;00m mlines, path \u001b[38;5;28;01mas\u001b[39;00m mpath, transforms)\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_enums\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m JoinStyle, CapStyle\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# \"color\" is excluded; it is a compound setter, and its docstring differs\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# in LineCollection.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages/matplotlib/lines.py:17\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01martist\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Artist, allow_rasterization\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcbook\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     16\u001b[39m     _to_unmasked_float_array, ls_mapper, ls_mapper_r, STEP_LOOKUP_MAP)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmarkers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MarkerStyle\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpath\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Bbox, BboxTransformTo, TransformedPath\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages/matplotlib/markers.py:147\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;66;03m# special-purpose marker identifiers:\u001b[39;00m\n\u001b[32m    143\u001b[39m (TICKLEFT, TICKRIGHT, TICKUP, TICKDOWN,\n\u001b[32m    144\u001b[39m  CARETLEFT, CARETRIGHT, CARETUP, CARETDOWN,\n\u001b[32m    145\u001b[39m  CARETLEFTBASE, CARETRIGHTBASE, CARETUPBASE, CARETDOWNBASE) = \u001b[38;5;28mrange\u001b[39m(\u001b[32m12\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m _empty_path = \u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mMarkerStyle\u001b[39;00m:\n\u001b[32m    151\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    152\u001b[39m \u001b[33;03m    A class representing marker types.\u001b[39;00m\n\u001b[32m    153\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    164\u001b[39m \u001b[33;03m        The supported fillstyles.\u001b[39;00m\n\u001b[32m    165\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages/matplotlib/path.py:152\u001b[39m, in \u001b[36mPath.__init__\u001b[39m\u001b[34m(self, vertices, codes, _interpolation_steps, closed, readonly)\u001b[39m\n\u001b[32m    150\u001b[39m \u001b[38;5;28mself\u001b[39m._codes = codes\n\u001b[32m    151\u001b[39m \u001b[38;5;28mself\u001b[39m._interpolation_steps = _interpolation_steps\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m readonly:\n\u001b[32m    155\u001b[39m     \u001b[38;5;28mself\u001b[39m._vertices.flags.writeable = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages/matplotlib/path.py:203\u001b[39m, in \u001b[36mPath._update_values\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_update_values\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     \u001b[38;5;28mself\u001b[39m._simplify_threshold = \u001b[43mmpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrcParams\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mpath.simplify_threshold\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    204\u001b[39m     \u001b[38;5;28mself\u001b[39m._should_simplify = (\n\u001b[32m    205\u001b[39m         \u001b[38;5;28mself\u001b[39m._simplify_threshold > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    206\u001b[39m         mpl.rcParams[\u001b[33m'\u001b[39m\u001b[33mpath.simplify\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    207\u001b[39m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._vertices) >= \u001b[32m128\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    208\u001b[39m         (\u001b[38;5;28mself\u001b[39m._codes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m np.all(\u001b[38;5;28mself\u001b[39m._codes <= Path.LINETO))\n\u001b[32m    209\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages/matplotlib/_api/__init__.py:218\u001b[39m, in \u001b[36mcaching_module_getattr.<locals>.__getattr__\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m props:\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m props[name].\u001b[34m__get__\u001b[39m(instance)\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m    219\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__module__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: module 'matplotlib' has no attribute 'rcParams'"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import udhr\n",
    "import matplotlib.pyplot as plot\n",
    "print(udhr.fileids())\n",
    "up=udhr.words('Polish_Polski-Latin2') # bierze jakis polski tekst\n",
    "print(up[:100]) # bierze pierwsze 100 slow z tego tekstu\n",
    "fqup=nltk.FreqDist(up) # liczy ile jest slow\n",
    "fqup.plot(30) # robi wykres ilosci wystepowania 30 slow ktore najczesciej sie powtarzaja\n",
    "v=fqup.keys() # bierze te 30 slow\n",
    "\n",
    "pnum_chars = len(udhr.raw('Polish_Polski-Latin2')) # liczy jakos surowo to\n",
    "pnum_words = len(udhr.words('Polish_Polski-Latin2')) # liczy ile jest slow\n",
    "pnum_sents = len(udhr.sents('Polish_Polski-Latin2')) # liczy ile jest zdan\n",
    "print (\"?\", pnum_chars, \"?\", pnum_words, \"?\", pnum_sents) # pokazuje wyniki\n",
    "print(\"?\", int(pnum_chars/pnum_words)) # pokazuje stosunek\n",
    "print( \"?\", int(pnum_words/pnum_sents)) # pokazuje stosunek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/mchojna/Documents/Studia/Magisterka/Semestr 2/Inżynieria lingwistyczna  INL/INL/PY_INL/lib/python3.12/site-packages (1.26.4)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.2.3-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Using cached numpy-2.2.3-cp312-cp312-macosx_14_0_arm64.whl (5.1 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.3 which is incompatible.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-2.2.3\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade numpy"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "PY_INL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
